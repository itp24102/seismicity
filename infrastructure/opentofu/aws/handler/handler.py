# handler.py
import os
import requests
import json
import boto3
from datetime import datetime
from geopy.geocoders import Nominatim
from geopy.exc import GeocoderTimedOut

S3_BUCKET = os.environ.get("S3_BUCKET")
S3_KEY_PREFIX = os.environ.get("S3_KEY_PREFIX", "events/")
AWS_REGION = os.environ.get("AWS_REGION", "eu-central-1")

s3_client = boto3.client("s3", region_name=AWS_REGION)
geolocator = Nominatim(user_agent="seismicity-lambda")

def reverse_geocode(lat, lon):
    try:
        location = geolocator.reverse((lat, lon), language="el", exactly_one=True, timeout=10)
        return location.address if location else "Î†Î³Î½Ï‰ÏƒÏ„Î· Ï„Î¿Ï€Î¿Î¸ÎµÏƒÎ¯Î±"
    except GeocoderTimedOut:
        return "Timeout"

def fetch_events_from_seismicportal(limit=20):
    url = f"https://www.seismicportal.eu/fdsnws/event/1/query?limit={limit}&format=geojson"
    response = requests.get(url, timeout=10)
    response.raise_for_status()
    data = response.json()

    events = []
    for feature in data["features"]:
        try:
            event_id = feature["id"]
            props = feature["properties"]
            coords = feature["geometry"]["coordinates"]

            timestamp = props["time"]
            magnitude = props["mag"]
            depth = coords[2]
            lon, lat = coords[0], coords[1]

            location = reverse_geocode(lat, lon)

            events.append({
                "id": event_id,
                "timestamp": timestamp,
                "magnitude": magnitude,
                "lat": lat,
                "lon": lon,
                "depth": depth,
                "location": location
            })
        except Exception as e:
            print(f"âš ï¸ Î Î±ÏÎ¬Î²Î»ÎµÏˆÎ· event Î»ÏŒÎ³Ï‰ ÏƒÏ†Î¬Î»Î¼Î±Ï„Î¿Ï‚: {e}")
    return events

def parse_and_upload(events):
    if not events:
        print("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î½Î­Î± ÏƒÏ…Î¼Î²Î¬Î½Ï„Î±.")
        return

    today = datetime.utcnow().strftime("%Y-%m-%d")
    key = f"{S3_KEY_PREFIX}{today}.json"

    try:
        old_data = s3_client.get_object(Bucket=S3_BUCKET, Key=key)["Body"].read().decode("utf-8")
        existing = json.loads(old_data)
    except s3_client.exceptions.NoSuchKey:
        existing = []

    existing_ids = {e["id"] for e in existing}
    new_events = [e for e in events if e["id"] not in existing_ids]

    if not new_events:
        print("â­ï¸ Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î½Î­Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ·.")
        return

    combined = existing + new_events
    s3_client.put_object(
        Bucket=S3_BUCKET,
        Key=key,
        Body=json.dumps(combined, ensure_ascii=False, indent=2).encode("utf-8"),
        ContentType="application/json"
    )
    print(f"âœ… Î‘Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎ±Î½ {len(new_events)} Î½Î­Î± ÏƒÏ…Î¼Î²Î¬Î½Ï„Î± ÏƒÏ„Î¿ {key}.")

def handler(event, context):
    print(f"ğŸŒ Polling Î±Ï€ÏŒ SeismicPortal: {datetime.utcnow().isoformat()}Z")
    try:
        events = fetch_events_from_seismicportal()
        parse_and_upload(events)
    except Exception as e:
        print(f"âŒ Î£Ï†Î¬Î»Î¼Î±: {e}")
    return {"statusCode": 200, "body": "Poll from SeismicPortal completed."}

lambda_client = boto3.client("lambda")

lambda_client.invoke(
    FunctionName="influx-writer",
    InvocationType="Event",
    Payload=json.dumps({"events": new_events}).encode("utf-8")
)
